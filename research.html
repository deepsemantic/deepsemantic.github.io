---
layout: page
title: Research
permalink: /research/
---
<!DOCTYPE html>
<html>
<head>
<meta name="viewport" content="width=device-width, initial-scale=1.2">
<style>
* {
  box-sizing: border-box;
}

/* Add a gray background color with some padding */
body {
  font-family: Arial;
  padding: 20px;
  background: #f1f1f1;
}
</style>
<h3>Recurrent Neural Networks</h3>
<p align="justify"> I am particularly interested in RNNs, recurrent memory mechanisms, and related learning machines, e.g. finite state machine, pushdown automaton, neural Turing machine.</p>

<br>
<br>
<h3>Machine Learning Interpretability</h3>
<p align="justify"> Making machine learning models (particularly deep neural models) more interpretable is challenging. This research work tries to achieve the following goals: (1) Interpretability, designing and developing methods that help us to understand the rules or patterns that model learned on training samples in a human-understandable way, e.g, automata extraction from RNNs. (2) Explainability, the methods should be able to give explanations for model predictions. (3) Uncertainty quantification, designing methods to estimate epistemic and aleatoric uncertainty with variational methods.</p>

<br>
<br>
<h3>Multimodal Deep Learning</h3>
<p align="justify"> This research work is to design and implement deep learning models/architectures to multimodal data analysis, e.g. image associated with a text description, video with audio information, text news accompanied with images et al... The analysis of multimodal data can tell us different aspects of information conveyed by data. On the other hand, their combination gives us more accurate knowledge and understanding of visual-textual or visual-auditory information</p>
</body>
</html>
